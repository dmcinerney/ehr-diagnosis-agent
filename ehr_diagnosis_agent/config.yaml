output_dir: /scratch/mcinerney.de/ehr-diagnosis-agent-output
data:
  path: /work/frink/mcinerney.de/datasets/mimic-iii/physionet.org/files/mimiciii/1.4/preprocessed
  dataset: reports_and_codes3
  max_reports_considered: 48
# write_to_cache_slice: null
write_to_cache:
  slice: '10000,20000'
  split: train
training:
  # limit_train_examples: null
  limit_train_size: 32 #10000
  limit_val_size: null
  resume_from: null
  # resume_from: /scratch/mcinerney.de/ehr-diagnosis-agent-output/wandb/run-20230615_171127-e0lpllft/files/ckpt_epoch=3_updates=135.pt
  # resume_from: /scratch/mcinerney.de/ehr-diagnosis-agent-output/wandb/run-20230615_171127-e0lpllft/files/ckpt_epoch=3_updates=135.pt
  # resume_from: /scratch/mcinerney.de/ehr-diagnosis-agent-output/wandb/run-20230616_122933-pp2dkyve/files/ckpt_epoch=17_updates=747.pt
  num_epochs: 100
  num_episodes: 32
  batch_size: 1
  accumulate_grad_batches: 32
  actor_lr: 1e-6
  # actor_lr: 1e-5
  # critic_lr: 3e-6
  critic_lr: 1e-5
  max_trajectory_length: null
  checkpoint_every: 1
  # objective_optimization: ppo_gae
  objective_optimization: supervised
  # objective_optimization: mix_objectives
  clear_gpu: true
  freeze_actor: null
  # freeze_actor: "everything_but_query"
  skip_risk_prediction: false
  # skip_risk_prediction: true
  skip_query_prediction: false
  # shape_reward_with_attn: false
  shape_reward_with_attn: true
  val_every: 5
  val_max_num_episodes: 5
  val_max_trajectory_length: null
eval:
  split: val
  limit_eval_size: null
  max_num_episodes: null
  max_trajectory_length: null
  # checkpoint: /scratch/mcinerney.de/ehr-diagnosis-agent-output/wandb/run-20230712_215840-ktr1ito1/files/ckpt_epoch=23_updates=753.pt
  checkpoint: /scratch/mcinerney.de/ehr-diagnosis-agent-output/wandb/run-20230717_000206-spuih2t3/files/ckpt_epoch=9_updates=279.pt
mix_objectives:
  coefficient: .5 # represents the proportion of the supervised objective
ppo_gae:
  gamma: 0.99
  lam: 0.95
  epsilon: .5
  sub_epochs: 1
  use_adv_norm: true
  # entropy_coefficient: .01
  entropy_coefficient: 0
  use_grad_clip: true
  log_reward: false
  # log_reward: true
  only_train_critic: false
  # only_train_critic: true
  only_train_query_prediction: true
supervised:
  sub_epochs: 1
  use_grad_clip: true
  entropy_coefficient: 0
  only_train_risk_prediction: true
  # only_train_risk_prediction: false
  query_supervision_type: targets
ppo_dae:
  epsilon: .5
env:
  llm_name: 'google/flan-t5-xxl'
  fmm_name: 'all-MiniLM-L6-v2'
  reward_type: 'continuous_independent'
  # reward_type: 'continuous_dependent'
  num_future_diagnoses_threshold: 1
  train_cache_path: /work/frink/mcinerney.de/ehr-diagnosis-agent/ehr_diagnosis_agent/.cache/env_train_cache_1
  # train_cache_path: /work/frink/mcinerney.de/ehr-diagnosis-agent/ehr_diagnosis_agent/.cache/env_train_cache_2
  val_cache_path: /work/frink/mcinerney.de/ehr-diagnosis-agent/ehr_diagnosis_agent/.cache/env_val_cache_1
  top_k_evidence: 3
  add_risk_factor_queries: false
  # add_risk_factor_queries: false
  limit_options_with_llm: true
actor:
  # type: normal
  type: dirichlet
  # type: beta
  normal_params:
    model_name: emilyalsentzer/Bio_ClinicalBERT
    diagnosis_bias: true
    use_attn: true
    # model_name: roberta-base
    embedding_batch_size: 32
    stddev_min: .02
    stddev_max: 1
  dirichlet_params:
    model_name: emilyalsentzer/Bio_ClinicalBERT
    diagnosis_bias: true
    use_attn: true
    # model_name: roberta-base
    embedding_batch_size: 32
    # concentration_min: .2
    concentration_min: 1
    # concentration_min: 5
  beta_params:
    model_name: emilyalsentzer/Bio_ClinicalBERT
    diagnosis_bias: true
    use_attn: true
    # model_name: roberta-base
    embedding_batch_size: 32
    concentration_min: 1
    init_concentration0: 100
critic:
  model_name: emilyalsentzer/Bio_ClinicalBERT
  diagnosis_bias: true
  # model_name: roberta-base
  embedding_batch_size: 32
